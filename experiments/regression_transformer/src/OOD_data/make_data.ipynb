{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0063f-31ab-400a-a993-f3e669f6cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from boom.datasets.SMILESDataset import *\n",
    "import pandas as pd\n",
    "import os\n",
    "##IMPORTANT: SELFIES must be version 1 to be compatible with pretrained IBM Regresion Transformer!\n",
    "import selfies as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b198f4d-1987-4c29-bf45-eeb5c4e56046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_wrapper(dataset, prop_name):\n",
    "    \"\"\"\n",
    "    Wraps the dataset into a pandas dataframe.\n",
    "    \"\"\"\n",
    "    num_samples = len(dataset)\n",
    "    df = pd.DataFrame(columns=[\"smiles\", prop_name])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        smiles, target = dataset[i]\n",
    "        df.loc[i] = [smiles, target]\n",
    "    return df\n",
    "\n",
    "def make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name):\n",
    "    \"\"\"\n",
    "    Takes in pandas dataframes and outputs a Regression Transformer input file for property prediction.\n",
    "    \"\"\"\n",
    "    #sf.set_semantic_constraints(\"hypervalent\")\n",
    "    data_min=min([min(train_df.iloc[:,1]),min(iid_test_df.iloc[:,1]),min(ood_test_df.iloc[:,1])])\n",
    "    data_max=max([max(train_df.iloc[:,1]),max(iid_test_df.iloc[:,1]),max(ood_test_df.iloc[:,1])])\n",
    "    if(property_token_name=='den'):\n",
    "        #Do train data\n",
    "        outfile='./10k_dft_density_OOD/10k_dft_density_OOD_train.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(train_df)):\n",
    "            normed_value = (train_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(train_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()\n",
    "    \n",
    "        #Make IID Test data\n",
    "        outfile='./10k_dft_density_OOD/10k_dft_density_OOD_iid_test.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(iid_test_df)):\n",
    "            normed_value = (iid_test_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(iid_test_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()\n",
    "        \n",
    "        #Make OOD Test data\n",
    "        outfile='./10k_dft_density_OOD/10k_dft_density_OOD_ood_test.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(ood_test_df)):\n",
    "            normed_value = (ood_test_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(ood_test_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()\n",
    "    \n",
    "    elif(property_token_name=='hof'):\n",
    "        #Do train data\n",
    "        outfile='./10k_dft_hof_OOD/10k_dft_hof_OOD_train.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(train_df)):\n",
    "            normed_value = (train_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(train_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()\n",
    "    \n",
    "        #Make IID Test data\n",
    "        outfile='./10k_dft_hof_OOD/10k_dft_hof_OOD_iid_test.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(iid_test_df)):\n",
    "            normed_value = (iid_test_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(iid_test_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()\n",
    "        \n",
    "        #Make OOD Test data\n",
    "        outfile='./10k_dft_hof_OOD/10k_dft_hof_OOD_ood_test.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(ood_test_df)):\n",
    "            normed_value = (ood_test_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(ood_test_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close() \n",
    "        \n",
    "    elif('qm9' in property_token_name):\n",
    "        #Do train data\n",
    "        outfile='./'+property_token_name+'_OOD/'+property_token_name+'_OOD_train.txt'\n",
    "        print(outfile)\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(train_df)):\n",
    "            normed_value = (train_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(train_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()\n",
    "    \n",
    "        #Make IID Test data\n",
    "        outfile='./'+property_token_name+'_OOD/'+property_token_name+'_OOD_iid_test.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(iid_test_df)):\n",
    "            normed_value = (iid_test_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(iid_test_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()\n",
    "        \n",
    "        #Make OOD Test data\n",
    "        outfile='./'+property_token_name+'_OOD/'+property_token_name+'_OOD_ood_test.txt'\n",
    "        file1 = open(outfile, 'w')\n",
    "        for index in range(len(ood_test_df)):\n",
    "            normed_value = (ood_test_df.iloc[:,1][index]-data_min) / (data_max-data_min)\n",
    "            selfies_string=sf.encoder(ood_test_df.iloc[:,0][index])\n",
    "            line='<' + property_token_name + '>' + '%0.3f' % normed_value + '|' + selfies_string + '\\n'\n",
    "            file1.write(line)\n",
    "        file1.close()     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39f210-bd99-4106-bcf1-3d866df09011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10k Density\n",
      "Done 10k HoF!\n",
      "./qm9_alpha_OOD/qm9_alpha_OOD_train.txt\n",
      "Done QM9 Alpha!\n",
      "./qm9_cv_OOD/qm9_cv_OOD_train.txt\n",
      "Done QM9 Cv!\n",
      "./qm9_gap_OOD/qm9_gap_OOD_train.txt\n",
      "Done QM9 Gap!\n",
      "./qm9_homo_OOD/qm9_homo_OOD_train.txt\n",
      "Done QM9 Homo!\n",
      "./qm9_lumo_OOD/qm9_lumo_OOD_train.txt\n",
      "Done QM9 Lumo!\n",
      "./qm9_mu_OOD/qm9_mu_OOD_train.txt\n",
      "Done QM9 Mu!\n",
      "./qm9_r2_OOD/qm9_r2_OOD_train.txt\n",
      "Done QM9 R2!\n",
      "./qm9_zpve_OOD/qm9_zpve_OOD_train.txt\n",
      "Done QM9 ZPVE!\n"
     ]
    }
   ],
   "source": [
    "#10k Density\n",
    "train_dataset = TrainDensityDataset()\n",
    "iid_test_dataset = IDDensityDataset()\n",
    "ood_test_dataset = OODDensityDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'density')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'density')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'density')\n",
    "os.makedirs('./10k_dft_density_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='den')\n",
    "print('Done 10k Density')\n",
    "\n",
    "#10k HoF\n",
    "train_dataset=TrainHoFDataset()\n",
    "iid_test_dataset=IDHoFDataset()\n",
    "ood_test_dataset=OODHoFDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'hof')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'hof')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'hof')\n",
    "os.makedirs('./10k_dft_hof_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='hof')\n",
    "print('Done 10k HoF!')\n",
    "\n",
    "#QM9_alpha\n",
    "train_dataset=TrainQM9_alphaDataset()\n",
    "iid_test_dataset=IDQM9_alphaDataset()\n",
    "ood_test_dataset=OODQM9_alphaDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_alpha')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_alpha')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_alpha')\n",
    "os.makedirs('./qm9_alpha_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_alpha')\n",
    "print('Done QM9 Alpha!')\n",
    "\n",
    "#QM9_cv\n",
    "train_dataset=TrainQM9_cvDataset()\n",
    "iid_test_dataset=IDQM9_cvDataset()\n",
    "ood_test_dataset=OODQM9_cvDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_cv')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_cv')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_cv')\n",
    "os.makedirs('./qm9_cv_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_cv')\n",
    "print('Done QM9 Cv!')\n",
    "\n",
    "#QM9_gap\n",
    "train_dataset=TrainQM9_gapDataset()\n",
    "iid_test_dataset=IDQM9_gapDataset()\n",
    "ood_test_dataset=OODQM9_gapDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_gap')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_gap')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_gap')\n",
    "os.makedirs('./qm9_gap_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_gap')\n",
    "print('Done QM9 Gap!')\n",
    "\n",
    "#QM9_homo\n",
    "train_dataset=TrainQM9_homoDataset()\n",
    "iid_test_dataset=IDQM9_homoDataset()\n",
    "ood_test_dataset=OODQM9_homoDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_homo')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_homo')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_homo')\n",
    "os.makedirs('./qm9_homo_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_homo')\n",
    "print('Done QM9 Homo!')\n",
    "\n",
    "#QM9_lumo\n",
    "train_dataset=TrainQM9_lumoDataset()\n",
    "iid_test_dataset=IDQM9_lumoDataset()\n",
    "ood_test_dataset=OODQM9_lumoDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_lumo')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_lumo')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_lumo')\n",
    "os.makedirs('./qm9_lumo_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_lumo')\n",
    "print('Done QM9 Lumo!')\n",
    "\n",
    "#QM9_mu\n",
    "train_dataset=TrainQM9_muDataset()\n",
    "iid_test_dataset=IDQM9_muDataset()\n",
    "ood_test_dataset=OODQM9_muDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_mu')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_mu')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_mu')\n",
    "os.makedirs('./qm9_mu_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_mu')\n",
    "print('Done QM9 Mu!')\n",
    "\n",
    "#QM9_r2\n",
    "train_dataset=TrainQM9_r2Dataset()\n",
    "iid_test_dataset=IDQM9_r2Dataset()\n",
    "ood_test_dataset=OODQM9_r2Dataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_r2')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_r2')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_r2')\n",
    "os.makedirs('./qm9_r2_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_r2')\n",
    "print('Done QM9 R2!')\n",
    "\n",
    "#QM9_zpve\n",
    "train_dataset=TrainQM9_zpveDataset()\n",
    "iid_test_dataset=IDQM9_zpveDataset()\n",
    "ood_test_dataset=OODQM9_zpveDataset()\n",
    "train_df = dataframe_wrapper(train_dataset, 'qm9_zpve')\n",
    "iid_test_df=dataframe_wrapper(iid_test_dataset, 'qm9_zpve')\n",
    "ood_test_df=dataframe_wrapper(ood_test_dataset, 'qm9_zpve')\n",
    "os.makedirs('./qm9_zpve_OOD',exist_ok=True)\n",
    "make_RT_inputs(train_df,iid_test_df,ood_test_df,property_token_name='qm9_zpve')\n",
    "print('Done QM9 ZPVE!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
